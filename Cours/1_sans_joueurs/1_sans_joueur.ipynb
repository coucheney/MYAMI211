{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cours 1: Jeux séquentiels sans joueurs\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "ou avec plusieurs joueurs dont les stratégies sont fixées.\n",
    "\n",
    "<div class=\"alert-info\">\n",
    "Classification des jeux:\n",
    "</div>\n",
    "\n",
    "* avec ou sans hasard:\n",
    "    * jeu déterministe: gain déterminé à l'avance (peu intéressant sans joueurs)\n",
    "    * jeu avec hasard: gain donné par une distribution de probabilité\n",
    "* type d'horizon:\n",
    "    * horizon fini: nombre d'étapes maximum borné\n",
    "    * horizon infini: nombre d'étapes maximum non borné\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Horizon fini avec hasard\n",
    "\n",
    "---\n",
    "\n",
    "**Exemple:** on lance un dé. On somme sa valeur à la somme des lancers précédents, et si on fait 6 on relance le dé. On relance au plus 2 fois le dé. Combien de points obtient-on en moyenne?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<center><img src='fig/finite_horizon.png'  style=\"width: 1000px;\"></center> \n",
    "\n",
    "\n",
    "Représentation sous forme d'**arbre**. Les valeurs $x$, $y$, et $z$ sont obtenues en remontant les calculs depuis les feuilles de l'arbre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Horizon infini avec hasard\n",
    "\n",
    "---\n",
    "\n",
    "**Exemple:** même jeu mais sans limite de relance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "**Remarque:** bien que le nombre *moyen* d'étapes est borné (vaut $\\frac65$), l'horizon est infini.\n",
    "\n",
    "\n",
    "<center><img src='fig/infinite_horizon.png'  style=\"width: 1000px;\"></center> \n",
    "\n",
    "Chaîne de Markov avec des gains sur les transitions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Modélisation: processus de récompense Markovien\n",
    "\n",
    "---\n",
    "\n",
    "* ensemble d'états $\\mathcal{S}$\n",
    "* matrice de transition $P$\n",
    "$$\\forall t \\geq0, P_{ss'} = \\mathbb{P}[S_{t+1} = s' | S_t = s] $$\n",
    "* fonction de récompense $r_{ss'}$ pour toute transition $s \\rightarrow s'$ ayant une proba positive\n",
    "* facteur de discount $\\gamma \\in [0,1]$\n",
    "\n",
    "<center><img src='fig/exemple_gamma.png'  style=\"width: 500px;\"></center> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Gain total** du processus $(S_t)_{t \\geq 0}$ \n",
    "\n",
    "\n",
    "$$G_0 = R_0 + \\gamma R_{1} + \\gamma^2 R_{2} + \\dots = \\sum_{k=0}^\\infty \\gamma^k R_{k}$$\n",
    "\n",
    "où $R_{k} = r_{ss'}$ où $s = S_{k}$ et $s' = S_{k+1}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Facteur de discount $\\gamma$\n",
    "\n",
    "---\n",
    "\n",
    "$$G_0 = R_0 + \\gamma R_{1} + \\gamma^2 R_{2} + \\dots $$\n",
    "\n",
    "* le gain total est fini si $\\gamma < 1$ et les récompenses sont bornées par $R_\\max$ car alors\n",
    "$$G_0 \\leq \\sum_{n \\geq 0} \\gamma^n R_\\max =  \\frac{R_\\max}{1-\\gamma}$$\n",
    "* garantie théorique de convergence: rend les applications contractantes (détails après);\n",
    "* peut permettre d'ajuster l'importance des récompenses proches vs lointaines (critère économique par exemple);\n",
    "* autre interprétation: $1-\\gamma$ peut être interprété comme une probabilité que le processus aille dans un état terminal (fictif) de récompense 0 à chaque transition, i.e. le jeu s'arrête;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Cas particulier des jeux stopping**:\n",
    "\n",
    "* stopping = il existe une probabilité $p$ et un entier $n$ tels que le jeu s'arrête sur un puits de valeur nulle avec une probabilité au moins $p$ en au plus $n$ étapes;\n",
    "\n",
    "* si il y a un nombre fini d'états, cela revient à ce que chaque état ait accès avec une proba non nulle à un puits de valeur nulle;\n",
    "\n",
    "* dans ce cas, et si les récompenses sont bornées, si on choisit $\\gamma = 1$ alors\n",
    "\n",
    "$$G_0 \\leq nR_\\max + (1-p) n R_\\max + (1-p)^2 nR_\\max+ \\dots \\leq \\frac{n R_\\max}{p} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fonction de valeur\n",
    "\n",
    "---\n",
    "\n",
    "C'est le gain total espéré en commençant dans l'état $s$\n",
    "\n",
    "$$v(s) = \\mathbb{E}[G_0 | S_0 = s] $$\n",
    "\n",
    "\n",
    "*Résoudre* un processus de récompense Markovien revient à calculer la fonction de valeur pour un ou tous les états.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exemple** (marche aléatoire sur un graphe)\n",
    "\n",
    "---\n",
    "\n",
    "On donne la chaîne de Markov suivante (stopping):\n",
    "\n",
    "<center><img src='fig/exemple_graph.png'  style=\"width: 1000px;\"></center> \n",
    "\n",
    "**Questions:** modéliser par un processus de récompense Markovien les deux problèmes suivants\n",
    "\n",
    "* quel est le temps moyen pour atteindre le puits $A$ ou $B$ en partant du sommet $C$?\n",
    "* quelle est la probabilité d'atteindre le sommet $B$ en partant de $C$?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Caractérisation de la valeur par un système linéaire\n",
    "\n",
    "---\n",
    "\n",
    "**Rappel**:\n",
    "\n",
    "$$v(s) = \\mathbb{E}[G_0 | S_0 = s] $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Caractérisation de la valeur**\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "v(s) & = \\mathbb{E}[G_0 | S_0 = s] \\\\\n",
    "& = \\sum_{s' \\in \\mathcal{S}} \\mathbb{P}[S_1 = s' | S_0 = s]\\mathbb{E}[G_0 | S_0 = s, S_1=s'] \\\\\n",
    "& = \\sum_{s' \\in \\mathcal{S}} P_{ss'}\\left( r_{ss'} + \\gamma \\mathbb{E}[G_1 | S_0 = s, S_1=s']\\right)\\\\\n",
    "& = \\sum_{s' \\in \\mathcal{S}} P_{ss'}\\left( r_{ss'} + \\gamma \\mathbb{E}[G_1 | S_1 = s']\\right)\\\\\n",
    "& = \\sum_{s' \\in \\mathcal{S}} P_{ss'} \\left( r_{ss'} + \\gamma v(s') \\right)\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "avec $G_1 = R_1 + \\gamma R_{2} + \\gamma^2 R_{3} + \\dots $\n",
    "\n",
    "**Question:** justifier chaque ligne\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exemple: temps d'atteinte de $s_0$\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='fig/exemple_exponentiel.png'></center> \n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "v_0 & = 0 \\\\\n",
    "v_1 & = \\frac12 (1 + v_0) + \\frac12 (1 + v_3)\\\\\n",
    "v_2 & = \\frac12 (1 + v_1) + \\frac12 (1 + v_3)\\\\\n",
    "v_3 & = \\frac12 (1 + v_2) + \\frac12 (1 + v_3)\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "**Solution:** \n",
    "\n",
    "$$(v_1, v_2, v_3) = (8, 12, 14) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Caractérisation matricielle de la valeur**\n",
    "\n",
    "---\n",
    "\n",
    "$$ v = R + \\gamma P v $$\n",
    "\n",
    "où $R = (R_s)_{s \\in S}$ et $R_s = \\sum_{s' \\in S} P_{ss'} r_{ss'}$\n",
    "\n",
    "* **Système linéaire** à résoudre (solution unique si $\\gamma < 1$ ou stopping): $O(n^3)$ et dans ce cas\n",
    "$$ v = (I - \\gamma P)^{-1} R $$\n",
    "\n",
    "* ok seulement pour des problèmes de petite taille (problème d'explosion combinatoire, cf jeu de l'oie avec 4 pions et 50 cases)\n",
    "* nécessite la connaissance complète du modèle c'est-à-dire la connaissance des matrices $P$ et $R$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercices\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Question 1:** \n",
    "\n",
    "\n",
    "Calculer la valeur du processus suivant, avec $\\gamma$ le facteur discount.\n",
    "\n",
    "\n",
    "<center><img src='fig/exemple_gamma.png'  style=\"width: 700px;\"></center> \n",
    "\n",
    "**Question 2:** \n",
    "\n",
    "\n",
    "Alice a $A$ euros et Bob $B$ euros. Ils lancent une pièce: si le résultat est pile, alors Alice prend un euro à Bob, sinon Bob prend un euro à Alice. Cette expérience est répétée jusqu'à ce que l'un des deux n'ait plus d'argent. Quelle est la probabilité que Bob soit ruiné à la fin?\n",
    "\n",
    "* modéliser cette situation par un processus de récompense Markovien\n",
    "* établir les équations à résoudre pour répondre à la question posée\n",
    "* résoudre les équations\n",
    "\n",
    "Question supplémentaire: quel est le nombre moyen d'étapes avant que l'un des deux protagonistes soit ruiné?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Calcul des valeurs par la méthode d'itération de valeur\n",
    "\n",
    "---\n",
    "La valeur est caractérisée par l'équation:\n",
    "$$ v = R + \\gamma P v $$\n",
    "\n",
    "Soit $f: \\mathbb{R}^S \\rightarrow \\mathbb{R}^S $ définie par\n",
    "$$ f(w) = R + \\gamma P w $$\n",
    "\n",
    "Sous l'hypothèse $\\gamma < 1$ ou stopping, on peut montrer que $f$ est une fonction contractante:\n",
    "$$\\|f(w_1) - f(w_2) \\|_\\infty \\leq \\gamma \\|w_1 - w_2 \\|_\\infty $$\n",
    "\n",
    "Par le théorème du point fixe de Banach:\n",
    "* la valeur est l'unique point fixe de $f$;\n",
    "* toute suite $(w_k)_k$ définie par $w_{k+1} = f(w_k)$ converge vers $v$;\n",
    "* la fonction de valeur peut être calculée de manière asynchrone à partir du moment où tout les états sont sélectionnés infiniment souvent:\n",
    "\n",
    "$$ \\tilde v(s) = \\sum_{s'}P_{ss'}(r_{ss'} + \\gamma \\tilde v(s'))$$\n",
    "\n",
    "le choix des états à mettre à jour peut être guidé par la chaîne de Markov P ou une autre chaîne irréductible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Itération de valeur sur un exemple\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='fig/exemple_exponentiel.png'></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.00 | 52.00 | 46.75 | 44.50 | 42.19 | 39.81 | 37.77 | 35.86 | 34.10 | 32.48 | 31.00 | 29.63 | 28.38 | 27.22 | 26.16 | 25.18 | 24.28 | 23.46 | 22.70 | 22.00 | 21.36 | 20.76 | 20.22 | 19.72 | 19.26 | 18.84 | 18.45 | 18.09 | 17.76 | 17.46 | 17.18 | 16.93 | 16.69 | 16.48 | 16.28 | 16.09 | 15.93 | 15.77 | 15.63 | 15.50 | 15.38 | 15.27 | 15.16 | 15.07 | 14.99 | 14.91 | 14.83 | 14.77 | 14.70 | 14.65 | 14.60 | 14.55 | 14.50 | 14.46 | 14.43 | 14.39 | 14.36 | 14.33 | 14.30 | 14.28 | 14.26 | 14.24 | 14.22 | 14.20 | 14.18 | 14.17 | 14.16 | 14.14 | 14.13 | 14.12 | 14.11 | 14.10 | 14.09 | 14.09 | 14.08 | 14.07 | 14.07 | 14.06 | 14.06 | 14.05 | 14.05 | 14.04 | 14.04 | 14.04 | 14.03 | 14.03 | 14.03 | 14.03 | 14.02 | 14.02 | 14.02 | 14.02 | 14.02 | 14.02 | 14.01 | 14.01 | 14.01 | 14.01 | 14.01 | 14.01 | "
     ]
    }
   ],
   "source": [
    "def iter_valeur(v):\n",
    "    return [1 + 0.5 * v[2], \n",
    "         1 + 0.5 * (v[0] + v[2]),\n",
    "         1 + 0.5 * (v[1] + v[2])]\n",
    "\n",
    "v = [50, 50, 50]\n",
    "for _ in range(100):\n",
    "    v = iter_valeur(v)\n",
    "    print(\"{:.2f}\".format(v[2]), end=\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 | 0.00 | 0.00 | 0.00 | 1.75 | 2.62 | 2.62 | 2.62 | 3.72 | 3.72 | 3.72 | 4.54 | 4.54 | 4.54 | 4.54 | 5.72 | 5.72 | 5.72 | 5.72 | 5.72 | 5.72 | 5.72 | 5.72 | 6.76 | 6.76 | 7.27 | 7.53 | 7.53 | 7.53 | 8.24 | 8.60 | 8.78 | 8.78 | 9.18 | 9.38 | 9.38 | 9.38 | 9.38 | 9.38 | 9.38 | 9.38 | 9.38 | 9.38 | 9.38 | 9.96 | 9.96 | 9.96 | 9.96 | 9.96 | 10.46 | 10.46 | 10.84 | 10.84 | 10.84 | 10.84 | 10.84 | 10.84 | 10.84 | 10.84 | 11.24 | 11.24 | 11.24 | 11.43 | 11.53 | 11.53 | 11.53 | 11.58 | 11.61 | 11.61 | 11.62 | 11.62 | 11.62 | 11.63 | 11.63 | 11.63 | 11.63 | 11.92 | 12.07 | 12.07 | 12.07 | 12.31 | 12.43 | 12.49 | 12.49 | 12.49 | 12.49 | 12.63 | 12.63 | 12.73 | 12.73 | 12.73 | 12.73 | 12.89 | 12.89 | 12.89 | 12.89 | 12.89 | 12.89 | 13.03 | 13.03 | 13.03 | 13.03 | 13.13 | 13.13 | 13.13 | 13.23 | 13.23 | 13.23 | 13.23 | 13.23 | 13.28 | 13.28 | 13.28 | 13.28 | 13.28 | 13.28 | 13.28 | 13.28 | 13.28 | 13.28 | 13.37 | 13.37 | 13.41 | 13.43 | 13.45 | 13.45 | 13.45 | 13.45 | 13.45 | 13.45 | 13.45 | 13.45 | 13.45 | 13.45 | 13.52 | 13.52 | 13.52 | 13.52 | 13.58 | 13.61 | 13.61 | 13.61 | 13.61 | 13.61 | 13.61 | 13.61 | 13.61 | 13.61 | 13.61 | 13.61 | 13.61 | 13.66 | 13.66 | 13.68 | 13.68 | 13.68 | 13.68 | 13.68 | 13.68 | 13.68 | 13.68 | 13.72 | 13.72 | 13.72 | 13.72 | 13.72 | 13.72 | 13.76 | 13.76 | 13.78 | 13.78 | 13.80 | 13.80 | 13.82 | 13.83 | 13.84 | 13.84 | 13.84 | 13.84 | 13.84 | 13.84 | 13.84 | 13.86 | 13.87 | 13.88 | 13.88 | 13.89 | 13.89 | 13.90 | 13.90 | 13.90 | 13.90 | 13.90 | 13.90 | 13.90 | 13.90 | 13.90 | 13.90 | 13.91 | 13.91 | "
     ]
    }
   ],
   "source": [
    "import random as rd\n",
    "\n",
    "def iter_valeur(v):   \n",
    "    res = [1 + 0.5 * v[2], \n",
    "         1 + 0.5 * (v[0] + v[2]),\n",
    "         1 + 0.5 * (v[1] + v[2])]\n",
    "    i = rd.randint(0,2)\n",
    "    v[i] = res[i]\n",
    "    \n",
    "v = [0, 0, 0]\n",
    "for _ in range(200):\n",
    "    iter_valeur(v)\n",
    "    print(\"{:.2f}\".format(v[2]), end=\" | \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Estimation de la valeur par la méthode de Monte Carlo (MC)\n",
    "\n",
    "---\n",
    "\n",
    "Estimer l'espérance du gain total avec la moyenne empirique: si on simule $k$ épisodes en partant de l'état $s$ et on obtient les gains $G^1_0, G^2_0, \\dots, G^k_0$  alors:\n",
    "\n",
    "$$ v(s) \\approx  \\frac1k \\sum_{i=1}^k G^i_0 $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* repose sur la **loi forte des grands nombres**: avec probabilité 1\n",
    "$$ \\mathbb{E}[G_0 | S_0 = s] = \\lim_{k \\rightarrow \\infty} \\frac1k \\sum_{i=1}^k G^i_0 $$\n",
    "car les variables $G^i_0$ sont iid.\n",
    "\n",
    "* **avantage**: ne nécessite pas la connaissance du modèle;\n",
    "* **restriction**: mais le processus doit s'arrêter;\n",
    "* **vitesse de convergence**: multiplier le nombre d'échantillons par 100 pour obtenir un chiffre significatif supplémentaire;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Algorithme de Monte Carlo première visite\n",
    "\n",
    "---\n",
    "\n",
    "Seule la première occurence d'un épisode est utilisé pour obtenir un échantillon.\n",
    "\n",
    "$$ v(s) \\approx \\frac1k \\sum_{i=1}^k G^i_{T_i(s)} $$\n",
    "\n",
    "où $T_i(s)$ est le premier instant où $s$ est visité pendant le i-ème épisode.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MC sur un exemple\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='fig/exemple_exponentiel.png'></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def step(d):\n",
    "    if random.choice([True, False]):\n",
    "        return d-1\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "def genere_temps():\n",
    "    pos, t = 3, 0\n",
    "    prem_passage = [-1]*3 + [0]\n",
    "    while pos > 0:\n",
    "        pos = step(pos)\n",
    "        t += 1\n",
    "        if prem_passage[pos] == -1:\n",
    "            prem_passage[pos] = t\n",
    "    return [t-e for e in prem_passage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Moyenne:  [0.0, 7.97215, 11.96136, 13.95393]\n"
     ]
    }
   ],
   "source": [
    "res = [0]*4\n",
    "nb_step = 100000\n",
    "for _ in range(nb_step):\n",
    "    t = genere_temps()\n",
    "    for i in range(4):\n",
    "        res[i] += t[i]\n",
    "for i in range(4):\n",
    "    res[i] = res[i] / nb_step\n",
    "print(\"\\nMoyenne: \", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Algorithme de Monte Carlo toutes visites\n",
    "\n",
    "---\n",
    "\n",
    "Chaque passage dans un état donne lieu à un échantillon, même dans le même épisode.\n",
    "\n",
    "$$ v(s) \\approx \\frac  {\\sum_{i=1}^k \\sum_{j=1}^{N_i(s)} G^i_{T_{i,j}(s)}}{\\sum_{i=1}^k N_i(s) } $$\n",
    "\n",
    "où \n",
    "* $N_i(s)$ est le nombre de passages dans l'état $s$ durant le i-ème épisode,\n",
    "\n",
    "* $T_{i,j}(s)$ est la date du j-ème passage dans l'état $s$ durant le i-ème épisode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def step(d):\n",
    "    if random.choice([True, False]):\n",
    "        return d-1\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "def genere_temps(nb_passage):\n",
    "    pos, t = 3, 0\n",
    "    dates = [[], [], [], [0]]\n",
    "    while pos > 0:\n",
    "        pos = step(pos)\n",
    "        t += 1\n",
    "        nb_passage[pos] += 1\n",
    "        dates[pos].append(t)\n",
    "    return [t*len(e) - sum(e) for e in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Moyenne:  [0.0, 8.007898977056232, 11.99807237952372, 13.995367120331974]\n"
     ]
    }
   ],
   "source": [
    "res = [0]*4\n",
    "nb_passage = [0]*4\n",
    "nb_step = 1000000\n",
    "for _ in range(nb_step):\n",
    "    nb_passage[3] += 1\n",
    "    t = genere_temps(nb_passage)\n",
    "    for i in range(4):\n",
    "        res[i] += t[i]\n",
    "for i in range(4):\n",
    "    res[i] = res[i] / nb_passage[i]\n",
    "print(\"\\nMoyenne: \", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Analyse des algorithmes de Monte Carlo sur un exemple\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='fig/MC_exemple.png'></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Questions**:\n",
    "\n",
    "* quelle est la valeur de l'état *cont*?\n",
    "* que retourne en moyenne un épisode avec la méthode de Monte Carlo première visite?\n",
    "* idem mais avec la méthode de Monte Carlo toutes visites?\n",
    "* montrer que cette méthode converge bien vers la valeur théorique quand le nombre d'épisodes augmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Autre formulation de l'algorithme de Monte Carlo première visite\n",
    "\n",
    "---\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\tilde v_{k+1} & = \\frac1{k+1} G^{k+1} + \\frac1{k+1} \\sum_{i=1}^k G^i  \\\\\n",
    " & =  \\frac1{k+1} G^{k+1} + \\frac{k}{k+1} \\frac1k \\sum_{i=1}^k G^i \\\\\n",
    " & =  \\frac1{k+1} G^{k+1} + \\frac{k}{k+1} \\tilde v_k \\\\\n",
    " & = \\tilde v_k + \\frac1{k+1}(G^{k+1} - \\tilde v_k)\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "* calcul incrémental possible avec un **pas décroissant** $\\frac1{k+1}$\n",
    "* on peut choisir un **pas constant** noté $\\alpha$ dans les environnements non stationnaires \n",
    "\n",
    "$$ \\tilde v_{k+1} = \\tilde v_k + \\alpha (G^{k+1} - \\tilde v_k) $$\n",
    "\n",
    "ce qui revient à calculer\n",
    "\n",
    "$$\\tilde v_k = \\alpha \\sum_{i=1}^k (1-\\alpha)^{k-i} G^i$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Temporal difference learning: TD(0)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "$$\\tilde v(S_t) \\leftarrow \\tilde v(S_t) + \\alpha_t (R_{t+1} + \\gamma \\tilde v(S_{t+1}) - \\tilde v(S_t)) $$\n",
    "\n",
    "* le paramètre $\\alpha_t$ est le **pas** de l'algorithme, pouvant être choisi constant\n",
    "* apprentissage à chaque transition en utilisant l'évaluation de l'état suivant (bootstrapping)\n",
    "* ne nécessite pas la connaissance du modèle\n",
    "* estimateur de la valeur:\n",
    "$$ R_{t+1} + \\gamma \\tilde v(S_{t+1}) $$\n",
    "biais mais de variance réduite par rapport à MC qui utilise $G_t$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### TD(0) sur un exemple\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='fig/exemple_exponentiel.png'></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def evalue(v):\n",
    "    d = 2\n",
    "    while d > -1:\n",
    "        d_sauv = d\n",
    "        d = avancer(d)\n",
    "        if d > -1:\n",
    "            v[d_sauv] += alpha * (1 + v[d] - v[d_sauv])\n",
    "        else:\n",
    "            v[d_sauv] += alpha * (1 - v[d_sauv])\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36 | 0.70 | 0.94 | 1.10 | 1.85 | 2.21 | 3.55 | 4.03 | 4.43 | 4.42 | 5.55 | 6.07 | 6.18 | 6.45 | 8.23 | 8.25 | 8.63 | 8.88 | 9.50 | 9.49 | 9.29 | 9.33 | 9.40 | 9.92 | 10.53 | 10.70 | 10.92 | 11.07 | 11.09 | 11.14 | 11.15 | 11.15 | 11.12 | 10.98 | 11.21 | 11.23 | 11.01 | 10.98 | 10.90 | 11.08 | 10.91 | 10.88 | 10.78 | 10.66 | 10.71 | 10.60 | 10.43 | 10.59 | 10.44 | 10.54 | 10.52 | 10.39 | 10.23 | 9.86 | 9.75 | 10.20 | 10.15 | 10.35 | 10.10 | 10.58 | 10.48 | 10.57 | 10.64 | 10.77 | 10.89 | 10.74 | 10.66 | 10.45 | 10.41 | 10.33 | 9.92 | 10.01 | 9.87 | 9.71 | 9.77 | 10.03 | 10.20 | 10.28 | 10.29 | 10.22 | 10.70 | 11.96 | 11.77 | 12.21 | 12.79 | 14.32 | 14.25 | 14.88 | 14.88 | 15.82 | 15.82 | 15.10 | 15.27 | 15.34 | 15.46 | 15.52 | 15.52 | 15.35 | 14.84 | 15.00 | 14.89 | 14.61 | 15.05 | 14.03 | 14.14 | 14.03 | 13.79 | 13.68 | 13.53 | 13.23 | 13.67 | 13.61 | 13.59 | 13.76 | 13.60 | 13.95 | 14.05 | 14.25 | 14.00 | 13.81 | 14.19 | 14.13 | 14.04 | 14.02 | 13.66 | 13.44 | 13.45 | 13.43 | 13.39 | 13.37 | 13.01 | 12.77 | 12.55 | 12.50 | 12.12 | 12.09 | 12.05 | 12.25 | 12.25 | 12.03 | 12.17 | 12.20 | 12.13 | 11.91 | 12.73 | 12.77 | 12.78 | 12.82 | 12.45 | 12.44 | 12.38 | 12.46 | 12.71 | 12.78 | 12.68 | 13.45 | 13.64 | 13.44 | 13.11 | 12.93 | 13.17 | 13.08 | 12.94 | 12.76 | 12.74 | 12.75 | 12.69 | 14.03 | 14.24 | 14.06 | 14.05 | 13.60 | 13.47 | 13.56 | 13.79 | 13.92 | 14.57 | 14.53 | 14.22 | 13.79 | 13.77 | 13.85 | 13.66 | 13.18 | 13.26 | 12.99 | 12.81 | 12.10 | 12.03 | 11.99 | 12.01 | 12.37 | 12.32 | 12.09 | 12.60 | 12.59 | 12.87 | 13.11 | 13.26 | 13.27 | "
     ]
    }
   ],
   "source": [
    "v = [0, 0, 0]\n",
    "alpha = 0.1\n",
    "for _ in range(200):\n",
    "    evalue(v)\n",
    "    print(\"{:.2f}\".format(v[2]), end=\" | \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**TD(0): convergence vers la valeur $v$**\n",
    "\n",
    "---\n",
    "\n",
    "$$\\tilde v(S_t) \\leftarrow \\tilde v(S_t) + \\alpha_t (R_{t+1} + \\gamma \\tilde v(S_{t+1}) - \\tilde v(S_t)) $$\n",
    "\n",
    "Sous les hypothèse de Robins Monro sur les pas $(\\alpha_t)_{t \\geq 0}$, typiquement $\\alpha_t = 1/(t+1)$:\n",
    "* $\\sum_{t \\geq 0} \\alpha_t = +\\infty$\n",
    "* $\\sum_{t \\geq 0} \\alpha_t^2 < +\\infty$\n",
    "\n",
    "$\\tilde v$ converge vers la valeur $v$, point fixe de l'application contractante \n",
    "$$ f(w) = R + \\gamma P w $$\n",
    "\n",
    "\n",
    "Le terme $R_{t+1} + \\gamma \\tilde v(S_{t+1})$ vaut en moyenne (avec $S_t = s$)\n",
    "$$ \\sum_{s'}P_{ss'}(r_{ss'} + \\gamma \\tilde v(s'))$$\n",
    "qui correspond à la fonction $f(\\tilde v)(s)$. \n",
    "\n",
    "* En moyenne on se rapproche de la fonction de valeur $v$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exemple: trajet retour du travail (exemple de Sutton, Barto)\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='fig/tab_driving_home.png'  style=\"width: 1000px;\"></center> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='fig/plot_driving_home.png'style=\"width: 1000px;\"></center> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Un exemple qui illustre la différence entre MC et TD(0)\n",
    "\n",
    "--- \n",
    "\n",
    "On observe les 8 épisodes suivants d'un processus de récompense Markovien:\n",
    "\n",
    "$$ \n",
    "\\begin{array}{l|l|l|l}\n",
    "(B, 0) & (B,1) & (B, 1) & (B, 1) \\\\ \\hline\n",
    "(B, 1)& (B,1) & (B, 1) & (A, 0), (B, 0)  \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Prédiction MC et TD(0) ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Pour les deux, $v(B) = 3/4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* pour MC, $v(A) = 0$\n",
    "* pour TD(0), $v(A) = 6/7$, et si on itère $v(A) \\rightarrow 3/4$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Différence entre MC et TD(0)\n",
    "\n",
    "---\n",
    "\n",
    "* MC donne la prédiction qui **minimise l'erreur aux données**;\n",
    "\n",
    "* (batch) TD(0) donne la prédiction obtenue par le **modèle Markovien le plus probable**;\n",
    "\n",
    "<center><img src='fig/max_like_example.png'></center> \n",
    "\n",
    "* en pratique, TD(0) converge plus rapidement;\n",
    "\n",
    "* le meilleur des 2 mondes avec l'algo TD($\\lambda$) qui interpole MC (avec $\\lambda = 1$) et TD(0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Références\n",
    "\n",
    "---\n",
    "\n",
    "* [cours de David Silver](https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver)\n",
    "\n",
    "* [Livre \"Reinforcement Learning: An Introduction\" de Sutton et Barto](http://www.incompleteideas.net/book/the-book-2nd.html)\n",
    "* [Livre \"Algorithms for Reinforcement Learning\" de Csaba Szepesvári](https://sites.ualberta.ca/~szepesva/rlbook.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "rise": {
   "theme": "beige"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
